{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exact_space",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQvY5Inp2f7e",
        "colab_type": "code",
        "outputId": "1cb2b027-6acc-417d-a6e4-73eaa9bd11a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-piCA9s8cMw",
        "colab_type": "text"
      },
      "source": [
        "#Creating New folders in the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYwq1K5-3box",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory. ' +  directory)\n",
        "        \n",
        "\n",
        "# Example\n",
        "createFolder('/content/gdrive/My Drive/Exact_space/new/asset_1/')\n",
        "createFolder('/content/gdrive/My Drive/Exact_space/new/asset_2/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4nG1cQy83HT",
        "colab_type": "text"
      },
      "source": [
        "#Extracting and Saving Video Frames using OpenCV-PythonPython"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js0ZvMbC_NWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting and Saving Video Frames using OpenCV-PythonPython for asset 1\n",
        "import cv2 \n",
        "# Opens the Video file\n",
        "cap= cv2.VideoCapture('/content/gdrive/My Drive/Exact_space/videos/class_1.mp4')\n",
        "i=0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('/content/gdrive/My Drive/Exact_space/new/asset_1/class_1_'+str(i)+'.jpg',frame)\n",
        "    i+=1\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqkvfxCBJSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting and Saving Video Frames using OpenCV-PythonPython for asset 2\n",
        "import cv2 \n",
        "# Opens the Video file\n",
        "cap= cv2.VideoCapture('/content/gdrive/My Drive/Exact_space/videos/class_2.mp4')\n",
        "i=0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('/content/gdrive/My Drive/Exact_space/new/asset_2/class_2_'+str(i)+'.jpg',frame)\n",
        "    i+=1\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJOzmIa_9MWy",
        "colab_type": "text"
      },
      "source": [
        "#Image Augmentation\n",
        "\n",
        "Random crop genarator for cropping the images\n",
        "\n",
        "Applying drop in the images -Sometimes there could be drop in signal\n",
        "\n",
        "Introducing noise -Incase if there is any disturbance in the Signal(mask)\n",
        "\n",
        "Blurring - If the video capture is not good or not clear  (dust,moisture,mist....)\n",
        "\n",
        "Introducing noise -Incase if there is any disturbance in the Signal(gaussian noise) -random noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeaJ0MaXcorp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random crop genarator for cropping the images\n",
        "def random_crop(img, random_crop_size):\n",
        "    # Note: image_data_format is 'channel_last'\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    return img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "\n",
        "def crop_generator(batches, crop_length):\n",
        "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
        "        yield (batch_crops, batch_y)\n",
        "        \n",
        "\n",
        "\n",
        "#Importing imgaug \n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "#Applying drop in the images -Sometimes there could be drop in signal\n",
        "def apply_drop(batches):\n",
        "  \n",
        "  while True:\n",
        "    batch_x, batch_y = next(batches)\n",
        "    batch_drop = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], batch_x.shape[3])) \n",
        "    \n",
        "    for i in range(batch_x.shape[0]):\n",
        "        image_array = np.asarray(batch_x[i])\n",
        "        drop = iaa.CoarseDropout((0.0, 0.5), size_percent=(0.2, 0.5))\n",
        "        batch_drop[i] = drop.augment_image(image_array)\n",
        "    yield (batch_drop, batch_y)\n",
        "    \n",
        "    \n",
        "    \n",
        "# Introducing noise -Incase if there is any disturbance in the Signal(mask)\n",
        "import random\n",
        "\n",
        "def noising(image):\n",
        "    array = np.array(image)\n",
        "    i = random.choice(range(16,48)) # x coordinate for the top left corner of the mask\n",
        "    j = random.choice(range(16,48)) # y coordinate for the top left corner of the mask\n",
        "    array[i:i+16, j:j+16]=-1.0 # setting the pixels in the masked region to -1\n",
        "    return array\n",
        "def noise_generator(batches):\n",
        "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_noise = np.zeros((batch_x.shape[0], 64, 64, 3))\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            batch_noise[i] = noising(batch_x[i])\n",
        "        yield (batch_noise, batch_y)\n",
        "        \n",
        "        \n",
        "#Blurring -If the video capture is not good or not clear       \n",
        "def blur_crop_flip_image(batches, blur_value, crop_value, flip_value):\n",
        "  seq = iaa.Sequential([\n",
        "    iaa.GaussianBlur(sigma=(0, blur_value)), # ex: 0.4\n",
        "    iaa.Crop(percent=(0, crop_value)), # ex: 0.2\n",
        "    iaa.Sometimes(0.3, iaa.Fliplr(flip_value))]) # 50% flip / horizontal flip of only 30% of the images passed\n",
        "  while True:\n",
        "    batch_x, batch_y = next(batches)\n",
        "    batch_augmented = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], NUM_CHANNELS)) \n",
        "    # NOTE: imgaug works on color images (3 channels). doesn't work on greyscale images with one channel\n",
        "    batch_augmented = seq.augment_images(batch_x) # calling ImgAug's augmentation on a batch of images\n",
        "    yield (batch_augmented, batch_y)\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "#Introducing noise -Incase if there is any disturbance in the Signal(gaussian noise)\n",
        "from skimage.util import random_noise\n",
        "\n",
        "## Applying Salt and Pepper noise in images.\n",
        "\n",
        "def apply_noise(batches):\n",
        "  \n",
        "  while True:\n",
        "    batch_x, batch_y = next(batches)\n",
        "    batch_noise = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], batch_x.shape[3])) \n",
        "    \n",
        "    for i in range(batch_x.shape[0]):\n",
        "        image_array = np.asarray(batch_x[i])\n",
        "        batch_noise[i] = random_noise(image_array , mode='gaussian', var =0.01)\n",
        "    yield (batch_noise, batch_y)\n",
        "    \n",
        "# train_generator = apply_noise(train_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Muw7fe3AQ8S",
        "colab_type": "text"
      },
      "source": [
        "###Zoom out, Horizontal shift, Vertical shift, Horizontal flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgaQrkZYBWym",
        "colab_type": "code",
        "outputId": "c1d14242-2228-4c61-bd36-38e29cd3d215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen1 = ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=20,\n",
        "                                  fill_mode='nearest',\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "train_datagen2 = ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=20,\n",
        "                                  fill_mode='nearest',\n",
        "                                  zoom_range = (2,2),\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "train_datagen3 = ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=20,\n",
        "                                  fill_mode='nearest',\n",
        "                                  width_shift_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "train_datagen4 = ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=20,\n",
        "                                  fill_mode='nearest',\n",
        "                                  height_shift_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tr_1 = train_datagen1.flow_from_directory('/content/gdrive/My Drive/Exact_space/exact_space/train/',\n",
        "                                           target_size=(256, 256),\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True,\n",
        "                                           class_mode='categorical')\n",
        "tr_2 = train_datagen2.flow_from_directory('/content/gdrive/My Drive/Exact_space/exact_space/train/',\n",
        "                                           target_size=(256, 256),\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True,\n",
        "                                           class_mode='categorical')\n",
        "tr_3 = train_datagen3.flow_from_directory('/content/gdrive/My Drive/Exact_space/exact_space/train/',\n",
        "                                           target_size=(256, 256),\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True,\n",
        "                                           class_mode='categorical')\n",
        "tr_4 = train_datagen4.flow_from_directory('/content/gdrive/My Drive/Exact_space/exact_space/train/',\n",
        "                                           target_size=(256, 256),\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True,\n",
        "                                           class_mode='categorical')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 858 images belonging to 2 classes.\n",
            "Found 858 images belonging to 2 classes.\n",
            "Found 858 images belonging to 2 classes.\n",
            "Found 858 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsGIiGE3Aspv",
        "colab_type": "text"
      },
      "source": [
        "###The videos are of different time lengths .\n",
        "\n",
        "###Inorder to have balanced classes , I took 429 images from each class for training and 5 from each class for testing . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z-u1dpueAnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_5 = blur_crop_flip_image(tr_4, 0.3, 0.3, 230)\n",
        "tr_6= (apply_noise(tr_4))\n",
        "tr_7 = crop_generator(tr_2,230)\n",
        "tr_8 = crop_generator(apply_noise(tr_1),230)\n",
        "\n",
        "tr_9 = noise_generator(tr_2)\n",
        "tr_10 = apply_drop(tr_3)\n",
        "\n",
        "\n",
        "\n",
        "from itertools import chain\n",
        "train_datagen = chain(tr_1,tr_2,tr_3,tr_4,tr_5,tr_6,tr_7,tr_8,tr_9,tr_10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcKiHeYcB7Vs",
        "colab_type": "text"
      },
      "source": [
        "###The actual images resolutions are 640x352\n",
        "###And we are reducing it to 256x256(occupies less memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftzaUiiHGMdf",
        "colab_type": "code",
        "outputId": "ec1fdc1a-953e-4392-f2ce-70e895a0cdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255\n",
        "                                 )\n",
        "\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/gdrive/My Drive/Exact_space/exact_space/test/',\n",
        "                                            target_size=(256, 256),\n",
        "                                            batch_size=8,\n",
        "                                            shuffle=True,\n",
        "                                            class_mode='categorical')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHWBoRGGj-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing modules\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D,Flatten,SeparableConv2D\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from keras.layers import Activation\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "from keras.layers import DepthwiseConv2D\n",
        "\n",
        "from keras.layers import SeparableConv2D\n",
        "\n",
        "from keras import regularizers\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFdTIs2BDEgP",
        "colab_type": "text"
      },
      "source": [
        "#Simple image classification model\n",
        "\n",
        "As the images are easy to classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p578blfXWbQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ade963a1-2db7-4cec-e88b-d641ceb0c930"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SeparableConv2D(16,3, 3, activation='relu', input_shape=(256,256,3)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(SeparableConv2D(32,3,3,activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(SeparableConv2D(32,3,3,activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(SeparableConv2D(2,124))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(16, (3, 3), activation=\"relu\", input_shape=(256, 256,...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(32, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(32, (3, 3), activation=\"relu\")`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO7usiJXG4pG",
        "colab_type": "code",
        "outputId": "264a5321-ba72-4264-ccc3-b37ba506f30f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "separable_conv2d_1 (Separabl (None, 254, 254, 16)      91        \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 254, 254, 10)      170       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 252, 252, 32)      442       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 252, 252, 10)      330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 126, 126, 10)      0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 124, 124, 32)      442       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 124, 124, 10)      330       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 1, 1, 2)           153782    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 155,587\n",
            "Trainable params: 155,587\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQh8mIowWZmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dut_GEt3G-cY",
        "colab_type": "code",
        "outputId": "3af5fcdf-212a-41f0-ed3d-3c4f8c52ca44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit_generator(train_datagen, epochs=10, steps_per_epoch=8, validation_steps=3,\n",
        "                    shuffle=True,\n",
        "                    validation_data=test_set)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 5s 668ms/step - loss: 0.6832 - acc: 0.5807 - val_loss: 0.6945 - val_acc: 0.4167\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 5s 633ms/step - loss: 0.5959 - acc: 0.7617 - val_loss: 0.4844 - val_acc: 1.0000\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 5s 644ms/step - loss: 0.3261 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 1.0000\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 5s 638ms/step - loss: 0.0760 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 1.0000\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 5s 641ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 5s 650ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.9782e-04 - val_acc: 1.0000\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 5s 646ms/step - loss: 4.3068e-04 - acc: 1.0000 - val_loss: 5.6010e-04 - val_acc: 1.0000\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 5s 651ms/step - loss: 3.0769e-04 - acc: 1.0000 - val_loss: 3.0192e-04 - val_acc: 1.0000\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 6s 696ms/step - loss: 1.4899e-04 - acc: 1.0000 - val_loss: 1.8238e-04 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 6s 699ms/step - loss: 5.3720e-05 - acc: 1.0000 - val_loss: 1.3202e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbf72dc1be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7w2M14ZEgV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1a7539c-6d78-4983-9de8-3441a0b76fb8"
      },
      "source": [
        "# scores = model.evaluate_generator(test_set,10) #1514 testing images\n",
        "# print(\"Accuracy = \", scores[1])\n",
        "\n",
        "\n",
        "pred=model.predict_generator(test_set,steps=2,verbose=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 42ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcQL1chZG4S9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7c11e061-77ff-498a-de29-e8a95930a19d"
      },
      "source": [
        "pred"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.9059693e-05, 9.9991095e-01],\n",
              "       [9.9979466e-01, 2.0537726e-04],\n",
              "       [5.8681180e-05, 9.9994135e-01],\n",
              "       [9.9979347e-01, 2.0652779e-04],\n",
              "       [3.7994505e-05, 9.9996197e-01],\n",
              "       [9.7783632e-05, 9.9990225e-01],\n",
              "       [9.9979466e-01, 2.0537726e-04],\n",
              "       [9.9981636e-01, 1.8366578e-04],\n",
              "       [9.9978644e-01, 2.1363400e-04],\n",
              "       [9.9980205e-01, 1.9801801e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBnP6XqiEqie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = (test_set.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDAxtfyQF1lP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d8b53c05-a9b7-4bc3-cb87-2baca0207605"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['asset_2',\n",
              " 'asset_1',\n",
              " 'asset_2',\n",
              " 'asset_1',\n",
              " 'asset_2',\n",
              " 'asset_2',\n",
              " 'asset_1',\n",
              " 'asset_1',\n",
              " 'asset_1',\n",
              " 'asset_1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0JQ6Hc1GgxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}